\documentclass{article}
\usepackage{graphics}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{bm}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{float}
\author{Ruichen Wang}
\title{Ad Click Prediction}
\begin{document}
\maketitle
\begin{abstract}
There are a lot of algorithms designed for ad ctr prediction. Those algorithms take contextual and historical features as inputs, often combines massive feature engineering work, then predict whether or not the user will click some certain ads. Here I'd like to introduce the traditional solution and recent deep learing technic.
\end{abstract}

\tableofcontents
\section{Online Advertising and Linear Model Sparsity}
OGD , , 
\subsection{Online Gradient Descent (OGD)}
\subsection{Truncated Gradient (TG)}
truncated gradient\cite{DBLP:journals/jmlr/DuchiHS11}
\subsection{Forward-Backward Splitting (FOBOS)}
FOBOS\cite{DBLP:journals/jmlr/DuchiS09}
\subsection{Regularized Dual Averaging Algorithm (RDA)}
RDA\cite{DBLP:journals/jmlr/Xiao10}
\subsection{Follow the Regularized Leader (FTRL)}
FTRL \cite{DBLP:journals/corr/abs-1009-3240}
\section{No Linearity and Feature Engineering}
\subsection{FM}
\subsection{FFM}
\section{Incorporate with Deep Learing}
\subsection{FNN}
\subsection{PNN}
\subsection{Deep and Wide}
\subsection{DeepFM}
\subsection{DNN}

\bibliographystyle{plain}
\bibliography{ref}

\end{document}


























# Trees 相关总结

> - [Info Gain](#info-gain)
>> - [ID3](#id3)
>> - [C4.5](#c45)
>> - [CART](#cart)
## Info Gain

Entropy 熵是衡量信息混乱程度的一个指标。 定义为H(S)=&sum;
-plogp 。

将某一个特征A 进行二分后，原数据会产生为两个新的熵，加起来就是新的总熵值。
我们定义前后熵之间的差值就是信息增益。
InfoGain = H(S)-H(S|A)

## ID3

ID3就是InfoGain的直接应用, 因此不能处理特征值为连续的情况。 是采用贪心策略，每次取信息增益最大的特征进行分裂，一个特征可能分裂出n个分支。缺点也很明显，ID3会更偏向于在类别多的特征上分裂。

## C4.5

C4.5采用的是InfoGain Ratio。除以了一项特征本身的熵。这样对于类别多的特征就等于增加了一定的惩罚。C4.5还兼容了连续特征，做法就是对连续特征进行离散分桶。

## CART 

CART即分类回归树，可以解决分类或者回归问题。不再像之前算法那样多叉分裂。只使用二叉树，每次将数据切分为2份。

分类任务中，与熵类似，通过最小化Gini loss= 1-p<sup>2</sup>来衡量数据的纯度。回归任务中使用MSE loss。
